# DataS

## 动机
经研究发现，一个相对较小但高质量的数据集已被证明足以优化语言模型(LLM)的性能。
然而，如何筛选这些数据集并没有一个很好的标准【过往的筛选标准总结分类详见我们的blog】。

本项目旨在结合以往研究人员的代表性工作，从多个维度评估sft数据，并自动化过滤sft数据。
无论您是寻找参考资料和学习资源的研究人员，寻求该领域快速入门的初学者，还是想要使用此工具包来帮助您的业务的码农，它都是一个很好的选择。

我们通过探索不同方法来定量评估数据样例，从三个关键维度进行评估: 复杂性、质量和多样性。

本项目会持续更新，大家看到新论文也欢迎issues

## 更新计划
2024/01/30 龙年前夕，我们项目正式新建文件夹（X

2024/01/31 上传测试使用的main.py，方便在此基础上进行新score函数方法的实现

2024/02/09 po出我们的论文list及相关讲解


## 项目资源
main.py是主要pipeline
之后会补充流程图来更清晰的展示

我们主要实现score函数，格式：

example 是个字典，包含 instruction input output 

name = "yiapi"  用户控制识别模式。
'''
def function2score(example,name = "yiapi"):
    pass
    example["scores"] = {"yiapi":0.5,"ifd":0.6}
    return example
'''
