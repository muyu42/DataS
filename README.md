# DataS

## 动机
语言模型(LLM)的发展受到了极大的关注，但大参数模型带来的高训练成本也限制了其普及和应用。我们希望从降低LLM训练成本的角度来探索如何提高LLM的效率。

经研究发现，一个相对较小但高质量的数据集已被证明足以优化LLM的性能。所以我们使用以数据为中心的算法，希望从数据本身的角度探索如何减少LLM训练中使用的数据，以降低训练成本，提高数据使用效率。即从现有数据中检索最有用的核心样本，以帮助模型学习下游任务所需的知识，并仅用少量样本实现良好的性能。  

本项目旨在结合以往研究人员的代表性工作，从多个维度评估sft数据，并自动化过滤sft数据。
无论您是寻找参考资料和学习资源的研究人员，寻求该领域快速入门的初学者，还是想要使用此工具包来帮助您的业务的码农，它都是一个很好的选择。

我们通过探索不同方法来定量评估数据样例，从三个关键维度进行评估: 复杂性、质量和多样性。

本项目会持续更新，大家看到新论文也欢迎issues

## 更新计划
- [x] 2024/01/30 龙年前夕，我们项目正式新建文件夹
- [x] 2024/01/31 上传测试使用的main.py，方便在此基础上进行新score函数方法的实现
- [x] 2024/02/09 po出我们的论文list及相关讲解，并持续更新维护


## 项目资源
main.py是主要pipeline
之后会补充流程图来更清晰的展示

我们主要实现score函数，格式：

example 是个字典，包含 instruction input output 

name = "yiapi"  用户控制识别模式。

```python
def function2score(example,name = "yiapi"):
    pass
    example["scores"] = {"yiapi":0.5,"ifd":0.6}
    return example
```
