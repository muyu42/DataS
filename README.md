# DataS

## 动机
经研究发现，一个相对较小但高质量的数据集已被证明足以优化语言模型(LLM)的性能，其大小从数十万到仅仅1000个样本不等。
然而，在早期的研究中，构建这些数据集主要依靠启发式的自动化方法(例如从ChatGPT中提取)，或者人工选择样本。

本项目旨在结合以往研究人员的代表性工作，从多个维度评估sft数据，并自动化过滤sft数据。
无论您是寻找参考资料和学习资源的研究人员，寻求该领域快速入门的初学者，还是想要使用此工具包来帮助您的业务的码农，它都是一个很好的选择。

我们通过探索不同方法来定量评估数据样例，从三个关键维度进行评估: 复杂性、质量和多样性。

本项目会持续更新，大家看到新论文也欢迎issues

## 更新计划
2024/01/30 龙年前夕，我们项目正式新建文件夹（X

2024/02/09 po出我们的论文list及相关讲解


## 项目资源
main.py是主要pipeline
之后会补充流程图来更清晰的展示

我们主要实现score函数，格式：
def function2score(example,name = "yiapi"):
    '''
    example 是个字典，包含 instruction input output 三个key    （后续可以扩展
    name = "yiapi"  用户控制识别模式。

    '''
    pass
    example["scores"] = {"yiapi":0.5,"ifd":0.6}
    return example
